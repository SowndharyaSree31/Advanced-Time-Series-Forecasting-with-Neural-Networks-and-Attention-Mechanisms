# ============================================================
# Advanced Time Series Forecasting with Attention Mechanisms
# ============================================================

import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.metrics import mean_squared_error, mean_absolute_error
from torch.utils.data import Dataset, DataLoader
import math
import random

# ------------------------------
# Reproducibility
# ------------------------------
SEED = 42
np.random.seed(SEED)
torch.manual_seed(SEED)
random.seed(SEED)

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ============================================================
# 1. Synthetic Multivariate Time Series Data Generation
# ============================================================

def generate_time_series(n_steps=5000):
    t = np.arange(n_steps)

    # Trend
    trend = 0.0005 * t

    # Seasonality
    seasonal_1 = 2 * np.sin(2 * np.pi * t / 50)
    seasonal_2 = 1.5 * np.sin(2 * np.pi * t / 100)

    # Heteroscedastic noise
    noise_scale = 0.3 + 0.0003 * t
    noise = np.random.normal(0, noise_scale)

    # Target variable
    y = trend + seasonal_1 + seasonal_2 + noise

    # Exogenous variables
    x1 = np.cos(2 * np.pi * t / 30) + np.random.normal(0, 0.2, n_steps)
    x2 = np.sin(2 * np.pi * t / 70) + np.random.normal(0, 0.2, n_steps)

    data = np.stack([y, x1, x2], axis=1)
    return data


data = generate_time_series()

# ============================================================
# 2. Dataset Preparation
# ============================================================

SEQ_LEN = 60
HORIZON = 1

class TimeSeriesDataset(Dataset):
    def __init__(self, data):
        self.X = []
        self.y = []

        for i in range(len(data) - SEQ_LEN - HORIZON):
            self.X.append(data[i:i+SEQ_LEN])
            self.y.append(data[i+SEQ_LEN:i+SEQ_LEN+HORIZON, 0])

        self.X = torch.tensor(np.array(self.X), dtype=torch.float32)
        self.y = torch.tensor(np.array(self.y), dtype=torch.float32)

    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        return self.X[idx], self.y[idx]


train_size = int(0.8 * len(data))
train_data = TimeSeriesDataset(data[:train_size])
test_data = TimeSeriesDataset(data[train_size - SEQ_LEN:])

train_loader = DataLoader(train_data, batch_size=64, shuffle=True)
test_loader = DataLoader(test_data, batch_size=64, shuffle=False)

# ============================================================
# 3. Baseline Model: LSTM
# ============================================================

class LSTMModel(nn.Module):
    def __init__(self, input_dim, hidden_dim):
        super().__init__()
        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)
        self.fc = nn.Linear(hidden_dim, HORIZON)

    def forward(self, x):
        out, _ = self.lstm(x)
        out = out[:, -1, :]
        return self.fc(out)


# ============================================================
# 4. Attention-Based Model: Transformer
# ============================================================

class PositionalEncoding(nn.Module):
    def __init__(self, d_model, max_len=500):
        super().__init__()
        pe = torch.zeros(max_len, d_model)
        pos = torch.arange(0, max_len).unsqueeze(1)
        div = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))
        pe[:, 0::2] = torch.sin(pos * div)
        pe[:, 1::2] = torch.cos(pos * div)
        self.register_buffer("pe", pe.unsqueeze(0))

    def forward(self, x):
        return x + self.pe[:, :x.size(1)]


class TransformerModel(nn.Module):
    def __init__(self, input_dim, d_model=64, nhead=4, num_layers=2):
        super().__init__()
        self.embedding = nn.Linear(input_dim, d_model)
        self.pos_encoder = PositionalEncoding(d_model)

        encoder_layer = nn.TransformerEncoderLayer(
            d_model=d_model,
            nhead=nhead,
            batch_first=True
        )

        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers)
        self.fc = nn.Linear(d_model, HORIZON)

    def forward(self, x):
        x = self.embedding(x)
        x = self.pos_encoder(x)
        attn_out = self.transformer(x)
        return self.fc(attn_out[:, -1, :])


# ============================================================
# 5. Training & Evaluation Utilities
# ============================================================

def train_model(model, loader, epochs=10):
    model.train()
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    criterion = nn.MSELoss()

    for epoch in range(epochs):
        total_loss = 0
        for X, y in loader:
            X, y = X.to(DEVICE), y.to(DEVICE)
            optimizer.zero_grad()
            preds = model(X)
            loss = criterion(preds, y)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}/{epochs}, Loss: {total_loss / len(loader):.4f}")


def evaluate_model(model, loader):
    model.eval()
    preds, actuals = [], []

    with torch.no_grad():
        for X, y in loader:
            X = X.to(DEVICE)
            output = model(X).cpu().numpy()
            preds.append(output)
            actuals.append(y.numpy())

    preds = np.vstack(preds).flatten()
    actuals = np.vstack(actuals).flatten()

    rmse = math.sqrt(mean_squared_error(actuals, preds))
    mae = mean_absolute_error(actuals, preds)
    mape = np.mean(np.abs((actuals - preds) / actuals)) * 100

    return rmse, mae, mape


# ============================================================
# 6. Model Training
# ============================================================

lstm_model = LSTMModel(input_dim=3, hidden_dim=64).to(DEVICE)
transformer_model = TransformerModel(input_dim=3).to(DEVICE)

print("\nTraining Baseline LSTM")
train_model(lstm_model, train_loader)

print("\nTraining Attention-Based Transformer")
train_model(transformer_model, train_loader)

# ============================================================
# 7. Evaluation & Comparison
# ============================================================

lstm_metrics = evaluate_model(lstm_model, test_loader)
transformer_metrics = evaluate_model(transformer_model, test_loader)

print("\nModel Performance Comparison")
print("--------------------------------")
print(f"LSTM       -> RMSE: {lstm_metrics[0]:.4f}, MAE: {lstm_metrics[1]:.4f}, MAPE: {lstm_metrics[2]:.2f}%")
print(f"Transformer-> RMSE: {transformer_metrics[0]:.4f}, MAE: {transformer_metrics[1]:.4f}, MAPE: {transformer_metrics[2]:.2f}%")

# ============================================================
# 8. Attention Interpretability Discussion (Conceptual Output)
# ============================================================

print("""
Interpretability Discussion:
The Transformer model leverages self-attention to dynamically weight
historical time steps when making predictions. Unlike LSTMs that compress
information into a fixed hidden state, attention enables the model to focus
on relevant seasonal cycles and trend components across long horizons.
This allows practitioners to inspect attention scores to identify which
time steps most strongly influenced a forecast, improving transparency
and trust in production forecasting systems.
""")
